\documentclass[11pt]{article}
\usepackage{acl2012}
\usepackage{geometry}
\usepackage{latexsym}
\usepackage{amsmath}
\usepackage{multirow}
\usepackage{url}
%\usepackage[numbers]{natbib}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{float}
\usepackage{multicol}
\newgeometry{margin=2.85cm}
\DeclareMathOperator*{\argmax}{arg\,max}
\setlength\titlebox{3.8cm}    % Expanding the titlebox

\graphicspath{{../figures/}}

\title{{\small CS224W Final Project} \\ What is karma? Quantifying online influence and credibility}
\author{Thomas Dimson \\
  {\tt tdimson@cs.stanford.edu}
  \\\And
  Milind Ganjoo \\
  {\tt mganjoo@stanford.edu}
}
\date{}

\begin{document}
\maketitle

\newcommand{\citet}[1]{\cite{#1}}


\section{Introduction}
Many online communities explicitly publicize the concept of \textit{karma} or
\textit{reputation} for users, computed as a sum of positive votes by other members of
the community. These explicit measures are often seen as proxies for more
intangible notions such as \textit{influence} (the ability of a member to
persuade others) and \textit{credibility} (the trustworthiness of the user as an
member of the community). In this paper, we describe the range of network
characteristics, interactions, and temporal factors that affect the accumulation
of karma points. Using this, we build a model that predicts karma values.

This paper is organized as follows: we begin in by looking at prior studies of
interaction networks in~\ref{sec:prior}. Based on these studies, we gathered
data from the communities of \textit{Hacker News} and \textit{SuperUser} and
constructed interaction graphs. In Section~\ref{sec:model} we look at different
properties of these networks and how they relate to karma and reputation. Based
on these properties, we train classifiers in Section~\ref{sec:eval} that are able 
to identify high-karma individuals with a high degree of accuracy.

While our model is evaluated on datasets that contain an explicit
measure of karma, we are particularly motivated by the ability of the
model to generalize to \textbf{private} communities. For example, our findings
can be applied to e-mail interaction graphs to determine a private ``karma'' 
score for members of an organization.

\section{Prior Work}
\label{sec:prior}

Most prior literature focuses on the abstract quality of \textit{influence}.
Both \citet{bakshy2011everyone} and \citet{cha2010measuring} define
influence as the ability to generate cascades on the Twitter graph. The authors
use local feature of users (e.g.\ number of followers, number of tweets,
retweets, mentions) in order to predict the ability for users to generate
cascades.

\citet{cha2010measuring} emphasizes the topic-specificity of influence -- they challenge
the notion that there is a common set of ``influentials'' who have
broad-reaching impact on online communities. Instead, they demonstrate that for
many topics, such as political events, there are special interest groups like
bloggers and politicians that see higher retweet and mention scores than the
generally popular Twitter users.

In a very recent paper, \citet{movshovitzanalysis} consider the reputation
scheme on StackOverflow (based on upvotes and accepted answers). They 
attempt to identify expert users based on their contribution
patterns and use high reputation users for validation. The authors tried many 
techniques to improve their classifier performance including PageRank and
an SVD decomposition of their interaction graphs. Notably, they find
that PageRank does not contribute significantly to their performance
and use user features such as number of answers, questions and question-answer 
rations in their final random forest model. They are
able to achieve an Area under the Curve of 81\% when classifying users
with reputations of more than 2400.

\section{Dataset}
In this paper, we will be focusing on two relatively large internet communities:
\textbf{Hacker News} and the \textbf{StackExchange} family of
websites. On Hacker News, users submit technology-related stories as
\textit{submissions} which other users use as an anchor to threaded discussions.
A user's \textit{karma} is computed as a sum of up-votes to their stories and
comments.  The StackExchange family of websites are question-and-answer sites
where a user will post a question and solicit answers from the community. A
user's \textit{reputation} is a weighted sum based on the number of their
questions and answers that are accepted, and whether their comments and posts
are voted as helpful by the community.

Gathering data for Hacker News came with many challenges: there is no published
dump of hacker news data, and no official API. Fortunately, the creator
of ThriftDB has created HNSearch\footnote{\url{https://www.hnsearch.com/}} as a technology
demo for his database. In addition to a public website, there is an unofficial API
supporting search queries. Although the API is limited to collecting 
only 100 recent items, we were able to circumvent this by constructing queries with limited
date ranges. Over the course of a week, we extracted JSON files for every comment,
submission and user on Hacker News by repeatedly querying the API\@. To our knowledge,
ours is the only complete dump of this data available on the internet.

Collecting data for the StackExchange family of websites was relatively easier.
An anonymized data dump of the entire series of websites is released every three
months\footnote{http://www.clearbits.net/creators/146-stack-exchange-data-dump}
in XML format. We wrote a Python script to parse the XML data and extract
relevant fields. Our initial emphasis is on \textbf{Super User}, which is a website where
enthusiasts and power users users ask questions about various aspects of
computer software and hardware. We chose this website because the data
is smaller in size since the website is new relative to Stack Overflow, the first
website in the StackExchange network. For the final report, however, we will
also include analysis on StackOverflow data.

After collecting the raw data for both datasets, we created an SQLite database
with normalized columns for all the fields. We also created an interaction graph
by collecting $(\text{replier}, \text{parent poster})$ edges and then caching
the graphs on disk as a NetworkX structure. A summary of our datasets is
available in Table~\ref{tab:graphstats}. As a final step, we divided each dataset 
into train, validation and test sets at
a 70\%/15\%/15\% split. Our milestone results are reported on our validation
set.

\begin{table*}[t]
\begin{center}
\begin{tabular}{| r | l l |}
\hline
& \textbf{Hacker News} & \textbf{Super User} \\
\hline
Users (Nodes) & 175091 & 190781 \\
Replies (Edges) & 2747966 & 266673 \\
Average Karma / Reputation & 131.8 & 83.1 \\
Largest SCC Fraction & 43\% & 3.8\% \\
Largest WCC Fraction & 63\% & 46\% \\
\hline
\end{tabular}
\end{center}
\caption{Graph statistics for our implied interaction graphs}
\label{tab:graphstats}
\end{table*}

\section{Model and Features}
\label{sec:model}
Below we describe the karma and reputation distributions for both networks.
After establishing the nature of the data, we investigate the association 
between a number of features and karma/reputation. 

\subsection{Karma Distribution}
% Power law plots, etc.
\begin{figure*}[t]
\centering
\includegraphics[width=0.95\linewidth]{powerlaws}
\caption{Karma distributions in our datasets with fitted power law distributions}
\label{fig:powerlaws}
\end{figure*}

Figure~\ref{fig:powerlaws} shows a fitted power law distribution for our
reputation and karma distributions.
% Needs expansion - milind?

\subsection{Karma Cliques and Preferential Attachment}
\label{sec:karma_cliques}
One model that seems intuitive is that high reputation users
tend to attach to other high reputation users, forming so-called
\textit{karma cliques}. We initially tested this hypothesis by
logarithmatically-bucketing karma/reputation and computing 
\citet{newman2003mixing}'s assortiativity over karma levels. This yields
relatively low assortiativity of $0.015$ and $0.040$ on Hacker News
and SuperUser respectively. 

Beyond correlations, Figure~\ref{fig:karma_cliques}
shows a scatter plot of the average of neighboring karma. In both networks,
the mean average neighboring karma remains relatively constant at all
karma levels, although the variance shrinks as karma increases.
Super User's plot is dramatically different than Hacker News. While there is
no discernable pattern based on the anchor node's karma, there is a noticable
clustering between looking at inbound reputation and outbound reputation. We see
that the inbound reputation (people answering this post) tends to be much higher
than the outbound karma (the questioner's karma). This suggests two distinct
roles on SuperUser: the questioners and the answers. Hacker News does not
appear to have this distinction.

Based on our plots and our relatively low assortiativity score between karma, we
so \textit{no evidence of preferential attachment} between similar-karma nodes
on either network.


\begin{figure*}[t]
\centering
\includegraphics[width=\linewidth]{karma_cliques}
\caption{Scatter plot of average neighbor karma against the anchor node's karma. 
The lines represent the mean average neighbor karma at a given karma level.
Neighbor karma variance appears to shrink with larger anchor karma values.}
\label{fig:karma_cliques}
\end{figure*}

\begin{figure*}[t]
\centering
\includegraphics[width=0.9\linewidth]{correlation}
\caption{Pearson's corrrelation coefficient matrix for some of our features.
Notice the dramatic difference in the types correlations when switching
between Hacker News and SuperUser.}
\label{fig:correlation}
\end{figure*}

\subsection{Node Features}
% Time spent on the site, etc.

\subsection{Network Features}
% PageRank, Constraint, HITS, etc. This should be most of it

\subsubsection{Centrality}
\label{sec:centrality}
By definition, centrality measures correspond to a node's importance in the
graph and it is natural to assume that karma and reputation are proxies for
importance. In our analysis we looked at degree centrality, variants of
PageRank~\cite{page1999pagerank}, Hubs and
Authorities (HITS)~\cite{kleinberg1999authoritative}, betweenness and 
closeness. As we will see, our most (linearly) predictive features 
correspond to centrality in network-specific ways. 

Our analysis of Hacker News supports a blunt hypothesis: members of the Hacker
News community are \textit{contributors}, and contributions come in the form of
replying and receiving replies equally. In fact, the correlation coefficient 
between out-degree (number of posts) and in-degree is $0.995$. We then ask
\textit{are all contributors are equal?}. To answer this, we ran two variants of PageRank: 
vanilla and a version where transition probability is proportional 
to the number of replies. Our weighted variant is our most linearly predictive
feature for karma ($\rho = 0.85$ Vs. $\rho=0.79$ vanilla).
Figure~\ref{fig:correlation} shows that with the exception
of closeness, other centrality measures are highly correlated with karma.
Our hub score correlation is slightly lower than authority score which suggests
a slight bias for high quality content over replying to other quality
contributors.

Centrality measures on SuperUser further support the evidence of distinct
``questioner'' and ``answerer'' roles noted in Section~\ref{sec:karma_cliques}.
Unlike Hacker News, Figure~\ref{fig:correlation}, shows no clear linear
correlations between our centrality measures. In particular, PageRank and
authority scores do not correlate at all to reputation. In contrast, a user's
in-degree and hub is directly related. We constructed the SuperUser graph as
directed edges between answerer and poster which suggest that on SuperUser
\textit{it doesn't matter who answers you, it matters whether you answer others}.

Although betweenness also appears to play a role on SuperUser, we see that
both hub score and betweeneness both correlate with the out-degree of nodes.
We believe this is because the weak component structure outlined in 
Table~\ref{tab:graphstats}. Obviously, more shortest path will pass through a
node of high out-degree in a network that is primarily weakly connected.

\begin{figure}[h]
\centering
\includegraphics[width=\linewidth]{closeness}
\caption{Closeness distribution in both networks}
\label{fig:closeness}
\end{figure}

%Milind, can you add something here? I'm running out of stuff to say
Figure~\ref{fig:closeness} shows a closeness histogram between the two networks.
Although not particularly predictive of karma or reputation, the closeness
centrality distribution is similar in both networks. For Hacker News, it appears
that nodes are closer together in terms of shortest paths (closeness between
$0.3$ and $0.4$ for the majority of values), while on SuperUser nodes are
further away (near zero closeness for most values).


\subsubsection{Strength of Weak Ties}
%Milind, can you handle this section? It looks like there is some interesting
%non-linear stuff going on here but I don't fully understand network constraint


\subsection{Textual Features}
% LDA, Sentiment, etc.
Beyond weight, each edge in our interaction graphs are augmented with the
\textit{text} corresponding to the reply that was made. One would expect 
text (i.e.\ insightful replies and helpful answers) to play the largest role 
in influence and karma. As we'll see below, this isn't necessarily the case.


\subsubsection{Sentiment Analysis}
\label{sec:sentiment}
\begin{figure}[h]
\centering
\includegraphics[width=\linewidth]{text_polarity}
\caption{Sentiment scatter plot against karma / reputation}
\label{fig:sentiment}
\end{figure}

Figure~\ref{fig:sentiment} shows a scatter plot comparing user karma
against user sentiment. We compute user sentiment concatinating all
their replies together and running Python's pattern module \citet{de2012pattern}, 
which implements sentiment classification using a fixed sentiment lexicon.  Both
Hacker News and SuperUser have a slight positive bias (mean polarity of 0.11 and
0.07 respectively). Plotted on a log scale, we see a linear envelope enclosing
the means. As such, while polarity is not linearly correlated with karma,
\textit{it pays to toe the line}: there are no examples of extremely high karma
users that have large polarity deviations. Furthermore, all examples of
highly-biased users occur towards the lower end of the spectrum. Although
sentiment analysis is never perfect, it provides a quick way of ruling out users
as being big influencers.

\subsubsection{Topic Modelling}
Another axis of textual analysis is clustering the content of posts in terms of
broad categories or topics. To this end, we performed Latent Dirichlet
Allocation (LDA) \cite{blei2003latent} across user text. We wished to answer two
questions: \textit{are broader knowledge bases associated with higher karma?} and
\textit{are there different karma models across different topics?}

\begin{figure}[h]
\centering
\includegraphics[width=\linewidth]{lda_kl}
\caption{User text KL-Divergence with uniform distribution Vs. Karma}
\label{fig:lda_kl}
\end{figure}

In Figure~\ref{fig:lda_kl}, we try to measure whether having a broad knowledge
base is associated with higher karma. To this end, compare the KL-divergence of
a user's topic distribution with that of the uniform distribution and plot it
against reputation/karma. Plotted on a log scale we see a similar ``bow''
pattern between the two networks, showing a wide variance in KL-divergence 
with a trend downwards for high reputation. Although our evidence is much weaker
than that of sentiment in Section~\ref{sec:sentiment}, this pattern shows that
``important people'' in the communities tend to have broad knowledge bases which
we can exploit when trying to classify people.


The variance in KL-divergences of Figure~\ref{fig:lda_kl} suggests that there
are different karma models across topics. As a coarse method of evaluation, 
we examined the measure of average expected karma, which we defined per topic 
$t$ as
\begin{align*}
AEK_t = \frac{1}{n} \sum_{\text{node} i}^n P_t(i) * \text{Karma}(i)
\end{align*}

Per-topic, these measures can be compared with a baseline uniform average
expected karma (15 for hacker news and 8 for SuperUser). For SuperUser, we
notice a wide variance in the expected reputation across topics: the AEK lies in
the interval $[2.4, 13.3]$ depending on the topic. The lowest AEK values come
with topic 2 (2.4 AEK), associated with words such as \textit{column, excel cell, table
and formula} and topic 7 (3.5 AEK) associated with words such as \textit{router,
wireless, address, connected}. We can contrast this to the largest AEK value with topic 8
(13.3 AEK) associated with words such as \textit{memory, support, number,
process, performance and hardware}. Thus, on SuperUser more reputation mass is
associated with answering certain classes of problems: people tend to reward 
performance tips more than Microsoft Excel tips. Since the site bills itself for
``power users'', this matches our intuition for subjects on the site.

The Hacker News view of topic is less dramatic than SuperUser with values lying
on the interval $[10.4, 23.2]$. Here, the lowest topic (number 3 at 10.4
AEK) is associated with words such as \textit{energy, english, countries,
europe, water}. The highest topic (number 0 at 23.2 AEK) is associated with
words such as \textit{startups, customer, marketing, revenue, founders}. As
the Hacker News originated with a startup incubator this matchup seems to make
intuitive sense: more karma mass lies in topics central to the site.

In addition to having different karma models, we tried running a variant of
PageRank that walks the random graph according to LDA probabilities.
Unfortunately, PageRank vectors were highly correlated with each other and not
with karma.

\section{Evaluation}
\label{sec:eval}
We evaluated our model and statistics described in Section~\ref{sec:model}
within a \textit{karma prediction} task. Essentially, we remove the value of
karma from our dataset and then try to reconstruct it using leftover network
information. This allows us to validate our features and see how well they might
generalize to networks without an explicit notion of karma. In addition to 
determining the exact value of karma
(Section~\ref{sec:regression}) we also identified high-karma users in our
dataset via classification (Section~\ref{sec:classification}). Our results are
summarized in Table~\ref{tab:eval}.

\begin{table*}
\centering
\begin{tabular}{|r| l l l | l l l|}
\hline
      & \multicolumn{3}{c |}{\textit{Hacker News}} & \multicolumn{3}{c|}{\textit{SuperUser}}  \\
\textbf{Model} & \textbf{AUC} & \textbf{RMSE} & $\textbf{R}^2$ &
\textbf{AUC} & \textbf{RMSE} & $\textbf{R}^2$ \\
\hline
Baseline & 0.63  & 563.17 & 0.55 & 0.75 & 187.35 & 0.96 \\
Weighted PageRank & 0.71  & 485.44 & 0.67 & 0.74 & 185.26  & 0.97 \\
HITS & 0.71 & 505.69 & 0.638 & 0.72 & 185.47 & 0.97 \\
Constraint & 0.69 & 562.63 & 0.55 & 0.71 & 187.17 & 0.96 \\
Textual & 0.64 & 561.79 & 0.55 & 0.72 & 187.32 & 0.96 \\
All Features & \textbf{0.75} & \textbf{483.1} (RF) & \textbf{0.67} (RF) &
\textbf{0.78} & \textbf{184.89} & \textbf{0.97} \\
\hline
\end{tabular}

\caption{Evaluation results for regression and ``famous'' classification for
various feature combinations. AUC is the area under the precision/recall curve
for the high karma/reputation prediction task.
Except where specified, classification results use a Random Forest classifier
while regression uses ordinary least squares.}
\label{tab:eval}

\end{table*}

\subsection{Famous Prediction}
\label{sec:classification}

% Needs expansion
\begin{figure}[h]
\centering
\includegraphics[width=\linewidth]{classification_pr_curve}
\caption{Precision/Recall Curve for our best high-karma classifiers}
\label{fig:classification}
\end{figure}

In our famous prediction task, we determine how well we can predict users that
pass a certain threshold of karma. Our power law distributions 
in Figure~\ref{fig:powerlaws} suggest that we will have infinite moments, so we
chose to set a threshold based on the ``top 2.5\%'' of users 
(have more karma than 97.5\% of others) instead of looking at standard
deviations. This corresponds to thresholds set 1308 and 350 for 
Hacker News and SuperUser respectively. 
To capture non-lienarities in the data we use a random forest classifier and
evaluate our performance by the area under precision/recall curve.

We use a baseline model taken from \citet{movshovitzanalysis}, attempting to
classify famouse users by the length of time they have been members and the number
of posts they've made. As Table~\ref{tab:eval} shows, the performance on both
datasets is quite respectable: we can get up to 63\% AUC on HN and 75\% AUC on
SU by looking at just these features.

% Milind, can you expand on this? We just need a bit of description of the table
% We could also do error analysis to see wtf is up

\subsection{Karma/Reputation Regression}
\label{sec:regression}
% Needs expansion
\begin{figure}[h]
\centering
\includegraphics[width=\linewidth]{residuals}
\caption{Log-log plot of predicted Vs.\ actual karma/reputation values}
\label{fig:residuals}
\end{figure}

In our regression task, we attempt to predict karma values \textit{directly}
utilizing the same dataset as used in our famous prediciton task. Our
improvement patterns mostly match that of our classification although our scores
(as defined by RMSE) are seemingly poor. Figure~\ref{fig:residuals} shows a plot
of predicted karma/reputation Vs.\ actual karma/reputation. Here, we can see that
while we are relatively successful at identifying ``famous'' individuals, we are
much less successful with lower-karma users.

% Milind, can you expand on this a bit?

\section{Conclusion}
In this paper, we created a interaction network model that is able to accurately 
identify ``famous users'' in two disparate communities: Hacker News and
SuperUser. The network structure of these communities is quite different, with
Hacker News having users that tie together others into a large strongly
connected component whereas SuperUser users fall into roles of ``questioners''
and ``answerers'' that force the graph to be more disconnected. Despite the
differences in structure, we find that network \textit{centrality} measures are
the strongest indicators of a node's karma or reputation. Beyond centrality and 
almost without exception, high karma users have a large number of ``weak ties''
(as measured by \textit{constraint}) and act as bridges between 
different parts of the network (large \textit{betweeneness}). In additinon to
network properties, we find that although there are some differences in karma
models between \textit{topics} of discussion, most high-karma users have broad
knowledge bases with neutral sentiment. 

We are most excited about how these findings could apply beyond networks with an
explicit notion of karma, and look forward to analyzing more private datasets in
further studies.

\bibliography{report}{} \bibliographystyle{acl2012}

\end{document}
