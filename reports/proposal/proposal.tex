\documentclass[10pt]{article}
\usepackage{geometry}
\usepackage{latexsym}
\usepackage{amsmath}
\usepackage{multirow}
\usepackage{url}
\usepackage[numbers]{natbib}
\newgeometry{margin=2.80cm}

\title{
  {\large CS224W Reaction Paper \& Project Proposal} \\
  What is karma? Quantifying online influence and credibility
}
\author{
  Thomas Dimson \\ {\tt tdimson@cs.stanford.edu}
  \and
  Milind Ganjoo \\ {\tt mganjoo@cs.stanford.edu}
}
\date{}

\begin{document}
\maketitle

\section{Introduction}
Many online communities explicitly publicize the concept
of \textit{karma} or \textit{reputation} for users, computed as a sum of votes
by other members of the community. In general, these explicit measures are seen
as proxies for more intangible notions such as \textit{influence} (the ability
of a member to persuade others) and \textit{credibility} (the trustworthiness
of the user as an upstanding member of the community). Specifically, one can 
imagine a range of network
characteristics, interactions, and temporal factors that affect the
accumulation of karma points. In our work, we will investigate whether such
factors can be identified and analyzed, and as a result, whether
karma values can be predicted.

This topic is motivated by the discussions in class about how users evaluate
each other in social graphs. We wish to determine whether karma be regarded
as something beyond a mere collection of votes. Success in building a model for
karma could inform a general framework for quantifying influence and credibility
on other graphs (including those without \textit{users} as nodes).

\section{Literature review}

There is a wealth of existing literature on identifying and quantifying
so-called \textit{influentials} on social networks such as Twitter. We believe
that many of the techniques used in such papers could be used in our analysis of
user karma.

\subsection{Everyone's an influencer: quantifying influence on Twitter \citep{bakshy2011everyone}}

\citet{bakshy2011everyone} define \textit{influence} as the ability to generate
cascades containing URLs on Twitter. Technically, they begin by examining the
first tweet (seed) containing the URL and then measure how the URL propagates
through the seed user's follower tree. To measure their success, they train a
model that attempts to predict cascades based on attributes of the user (e.g.,
number of followers or the number of tweets) and their past ability to generate
cascades.  Unsurprisingly, the past ability to predict cascades was the best
predictor of future performance.

A big take-away from this paper is that local features -- those from a user's
immediate followers -- are better indications of influence than global ones
(wider properties of the graph). The authors also use Mechanical Turk to
categorize tweeted URs in an attempt to see if cascades are affected by the
\textit{content} of the tweets. They admit that this categorization did not help
in their prediction task. In our work, it seems worth investigating whether
\textit{karma} of repliers is a big indicator of the karma of the person posting
and whether there are ``karma cliques'' in the graph.

We take issue with two parts of the paper: first, the authors directly define
\textit{influence} as the ability to generate cascades. Influence is a nuanced
concept, and it seems that cascades may only be a small factor in it. We also
think that the authors' analysis of content in cascades is naive -- depending on
humans to evaluate content made their dataset subjective and limited.  Our
investigation could include a larger scale analysis of content in the form of a
topic modelling algorithn such as Latent Dirichlet Allocation (LDA)
\citep{blei2003latent}.

The authors' task differs from our task because unlike karma, influence is not
necessarily a directly observable quantity. That said, we believe that the
approach of the paper provides a direction for us: attempting to come up with a
model of karma and then quanitfying our success by our ability to predict it.

\subsection{Analysis of the Reputation System and User Contributions on a
  Question Answering Website: StackOverflow
  \citep{movshovitzanalysis}}

In this very recent paper, \citet{movshovitzanalysis} consider the reputation
scheme on StackOverflow (based on upvotes and accepted answers). They analyze 9
million questions and answers posted by 1.2 million users since the site's
inception and attempt to identify expert users based on their contribution
patterns.

One striking direction pursued by the paper is their PageRank analysis on
interaction graphs implied by the questioner and answerer (stratified into three
different graphs based on whether the answer was upvoted, accepted, or neither).
They attempted to find important nodes (users) through this approach. However,
they observed that reputation scores are not as correlated with PageRank values
as they had originally thought -- many users with high reputation had
considerably lower PageRank.

In addition to PageRank, the paper attempts to find anomalous users by running
SVD on the interaction graphs, which yielded a few anomalous questioner and
answerer users, who gained extremely large reputations and had highly focussed
ego networks, mainly through only one type of contribution (i.e. either a
question or an answer). This illustrates the non-intersecting ways reputation
can be built, and informs an approach to filter out anomalies.

Finally, this paper builds a classification model to predict ``expert users'',
defined by them as users with reputation scores of more than 2400. They build a
binary classification model based on simple user features like number of answers,
questions, accepted answers, upvoted answers and comments, and question-answer
ratios, and run random forest classification on that model. They obtain an Area
under the Curve of 81\%, which they claim is higher than previous attempts.

One of the shortcomings of this paper is that while it notes the discrepancies
betwen reputation scores and PageRank, they did not attempt to explain them --
this is an area we would like to look into. Specifically, we would like to
perform topic-sensitive PageRank and LDA analysis (described in Section
\ref{sec:models}) to see if stronger correlation occurs in the context of
specific topics.  Additionally, we would like to perform other forms of
stratification, such as setting thresholds on interaction length, to calculate
PageRank in the context of long and potentially insightful interactions.

The PageRank-based methodology to identify user influence in this paper is so
far the closest to our proposed approach. However, instead of simply identifying
expert users through a classification task, we hope to build a generalizable
model to predict karma scores specific to different websites based on
per-website observations.  In addition, we plan to use some of their intuitive
conclusions -- such as the higher reputation earned by early users and frequent
contributors -- in forming an ambitious baseline for our evaluations.

\subsection{Measuring User Influence in Twitter: The Million Follower Fallacy
  \citep{cha2010measuring}}

Like \cite{bakshy2011everyone}, \citet{cha2010measuring} study a more practical
implication of influence -- the ability of a user to spread information to a
large network of nodes. The paper compares three measures of influence of
Twitter users: in-degree, number of retweets earned, and number of mentions.
They use the \textit{rank correlation coefficient} to compare measures of
influence:

\begin{equation}
  \rho = 1 - \frac{6\sum{(x_i - y_i)^2}}{N^3 - N}
\end{equation}

where $x_i$ and $y_i$ are the ranks of users based on two different influence
measures. Using this, they found that the users with high number of mentions
also get retweeted often, i.e. there is high correlation between retweet and
mention influence. However, in-degree (number of followers) was not related to
other measures, indicating that merely having a large number of followers says
nothing about the ability to practically engage with one's audience.

Another conclusion of this paper is that the users with highest mention
influence were usually famous people like celebrities (indicating the
\emph{name} value of mention influence), while high retweet influence was
associated with content aggregators like news accounts (indicating the
\emph{content} value of retweet influence).

The paper also emphasizes the topic-specificity of influence -- they challenge
the notion that there is a common set of ``influentials'' who have
broad-reaching impact on online communities. Instead, they demonstrate that for
many topics, such as political events, there are special interest groups like
bloggers and politicians that see higher retweet and mention scores than the
generally popular Twitter users.

The final contribution of this paper is a temporal analysis of influence. The
first is studying how influence wanes over time (measured by changing retweet
and mention probabilities $P$) when not maintained through regular engagement
with the community. The second is tracking the influence gains by select users
to explain the often meteoric rise in influence of topical posters during major
events.

\subsection{Brainstorming and Future Directions}
Two of our papers address the concept of influence in the Twitter graph, where it is
not directly observable. We are intrigued by their definition of influence as the ability
to create cascades of networks, but think that it might be better validated on a graph
that has an explicit notion of \textit{influence}.

% MILIND - this is kind of hacked together. Can you take a pass?

Our second paper has a much more quantitative analysis of reputation on StackOverflow.
Although they don't address cascades directly, we are intrigued by the structured approach
they take to their analysis and think it could apply nicely to our own techniques.
StackOverflow has a particularly complicated notion of reputation, which is not simply
a linear combination of up-votes to pieces of content. Analyzing a similar quantity
on more direct graphs (e.g., karma on Slashdot) might make for a more successful
model.

Furthermore, the paper has a concrete evaluation metric: the ability to predict 
``influentials'' (high karma individuals). We could try to pursue a similar direction,
but it makes more sense to us as a regression problem (predicting karma) than a classification
(predicting large karma).

All the literature we read contained a large descriptive section. This provided a very
natural progression between ideas and models. In our paper, we could start by first
looking at factors correlated with karma and then use this analysis as a base
for our model. Additionally we could also look at social interactions to see, for example,
if high karma users always reply to other high karma users.

%%%%%%%%%%%%%%%%%%
% Note: I will take a stab at this tomorrow. I have a few general brainstorming
% ideas from the above analysis.

% Our objective is similar -- we intend to study what
% Note 1: can we sift out
% users with high karma values but who are just popular because they've been
% around long, and not necessarily because they're useful?

% How do you measure
% "value" of their contributions? Can we study the nature of their relationships
% with others? (e.g. are they perceived positively by other high-ranked members?
% or is there a lot of antagonism/arrogance?)

% * Note 2: can we measure evolution
% of karma with time? Don't want "15 seconds of fame" people who've since then
% retained their influence, because karma scores are usually static.  *

%- indegree only final snapshot, couldn't use graph analysis, instead probabilty
%that a random tweet is a retweet or mention of a given user. we won't have that
%problem
%- most conclusion-rich paper, however many were based on empirical intuitions
%and were in retrospect (e.g. they admit that findings about temporal trends in
%influence is based only on the set of users who became popular, and manual
%inspection of their twee trends). We hope to perform a more rigorous graph-based
%analysis to see if our conclusions can be generalized across online communities.

\section{Project Proposal} \subsection{Problem Definition}
% What is the problem we are solving
Our term will be spent creating a mathematical model of user karma that is
validated by its ability to predict karma values for individual users. We want
to answer the question: is karma simply the sum of positive votes for a given
user, or is it also predicted by wider properties of the social graph?
Furthermore, is our model of karma specific to a single website or does it apply
more broadly across different datasets?  Finally, on sites that lack an explicit
model of karma (e.g. Wikipedia), does our model identify high-scoring nodes that
match our intuition?

\subsection{Data Sources}
% What data sources are we using and how will we collect it
We will be using multiple data sources in our project. As part of a past project
in Natural Language Understanding (CS224U), we crawled a large dataset of
conversation trees on the popular ``Hacker News''
(\url{https://news.ycombinator.com/}) website. On the site, users submit stories
(URLs) which are up-voted by other users. Each story is accompanied by comments,
in the form of a threaded conversation tree, which are also up-voted and
down-voted by different users. Each user on the site has a visible karma score,
which is the sum of all upvotes and downvotes that their comments and stories
have received.  We anticipate building a comment \textit{graph} of users where
directed edges represent the source replying to the target in a conversation.

As a secondary datasource, we would also like to analyze StackOverflow
(\url{http://stackoverflow.com/}). Here, a poster created a programming-related
question and solicits answers from the community. When satisfied, the poster
marks their question as ``solved''. Other members of the community can up-vote
or down-vote both questions and answers. Each user on the site has a
``reputation'', which is a weighted combination of up-votes, down-votes and
other factors such as question creation and closed answers. Fortunately,
StackOverflow makes all their data available online through their StackExchange
data explorer (\url{http://data.stackexchange.com/}) and we will not have to
perform any crawling to get access.

\subsection{Anticipated Work}
% What work do you plan to do the project?
Development of our project will begin with a \textit{descriptive} component. The
obvious first step is to take karma and visualize it: does it follow a power
law?  Is the power law different depending on the data source we analyze? Having
determined what karma looks like, we can start to see how it correlated to wider
properties of the graph. For example, we could look at how the clustering
coefficient varies with karma of the user.

After making sense of the data we are dealing with, we anticipate moving towards
our \textit{predictive} component. Guided by our earlier findings we will try to
create a model that is able to perform blind-prediction on karma. It seems
plausible that some of our early metrics could play the role of
\textit{features} in this system.

\subsection{Models and Algorithms}
\label{sec:models}
% Which algorithms/techniques/models you plan to use/develop? Be as specific as you can!
The final model we produce will likely be a regression model fit on top of
features that we identify in the descriptive phase of our project. Ideally, we
would be able to take the model we create for our \textit{Hacker News} dataset
and achieve similar results on our \textit{StackOverflow} dataset with a small tweak
in our parameters. If a regression model proves to be impossible due to the wide
variance in karma scores, we could also evaluate our success on a classification
task that attempts to divide users into high-karma (important contributors) and
low-karma users (unimportant contributors) by picking a fixed threshold of karma
scores.

We are particularly interested in exploring the role of \textit{content} in
karma. Specifically, we want to know if there are different karma distributions
for users depending on the topics that they normally discuss. We could
investigate this by computing topic-distributions for users through Latent
Dirichlet Allocation (LDA). We could then look at probability-weighted karma
distributions in each topic, and see if there is a wide variance between topics.
Depending on the answer, we could consider creating different models for each
topic. Furthermore, we could try to evaluate topic-coherence in the
neighborhoods around each node (do people talk to each other about the same
things?).

On the surface, PageRank feels like a natural fit for our task because it
generally corresponds to the \textit{authority} or \textit{influence} of nodes
in our graph. A component of our analysis will be to plot karma against PageRank
scores to see how predictive we can be.  Going deeper, we could combine our
LDA-topic analysis with PageRank by performing \citep{haveliwala2002topic} on 
our nodes and seeing if graph authority is
more predictive of karma within certain topics. This hypothesis was validated in
predicting following relationships on the twitter graph in
\citep{weng2010twitterrank}

\subsection{Evaluation}
% Who will you evaluate your method? How will you test it? How will you measure
% success?
Since karma is a directly observable, we will test our model in a
blind-prediction task. Concretely, we will run our model on a dataset without
looking at the ``gold'' karma scores and then evaluate our prediction quality
based on the average residual between the gold score and our predicted score.

We will frame the quality of our results by evaluating them against a simple
baseline: least squared regression using the number of replies by the poster and
length of time the poster has been a member of the site. According
to~\cite{movshovitzanalysis}, these were two strong indicators of reputation on
StackOverflow. 

\subsection{Submission}

Our final submission will address what the concept of \textit{karma} means on
different websites on the web. Our paper will begin by analyzing the
distribution of karma and proceed to correlate karma scores with basic graph
measurements (e.g., clustering coefficients). Guided by this analysis, we intend
to build up a mathematical model of karma and create a regression model for
prediction. This model will be evaluated in a blind-prediction task and measured
against a simple baseline. Time permitting, we will also apply our
model to a dataset where karma is latent and see how well it stacks up
against our intuition.
% such as?

\bibliographystyle{abbrvnat}
\bibliography{proposal}

\end{document}
